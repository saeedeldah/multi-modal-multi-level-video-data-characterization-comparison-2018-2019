# Multi-modal & Multi-level video data characterization & comparison 2019 - 2018

Multimedia big data are considered the largest and the fastest-growing amount of big data which
is considered nowadays the “biggest big data”. Moreover, one type of very spread multimedia data
is video. With a simple click on a cheap smartphone, you can produce a video and share it on
various social media. However, most of the shared videos have no information that describes them
unless the user tags the video with a specific type and some keywords that cannot be considered
as reliable. The analysis of the content of audiovisual content is the main step for better storage
solutions, video recommendation systems, profile construction, duplication detection (for rights
issues) and many other systems. Even though the work in this domain is not new, proposals fall
short to create an effective multimedia content analysis system, due to multiple issues such as the
using of subjective given data such as metadata and tags, or miss using the extracted features, for
instance simple sum up for features (ex. Audiovisual content analysis), with no synergy between
them. This work is a part of unified series of studies about grouping videos based on semantic
similarity induced from multiple modalities of audio, video, metadata, transcripts and social data
cooperation between Lebanese University and Université Toulouse III - Paul Sabatier. In this
report we provide full details of the work done during the internship period and the planned
methodology, along with video content structuring definitions, similarity measure, clustering
classification algorithms, and methods used. At the end a comparison of our results with other
works done on the MediaEval corpus (MediaEval) is presented.
